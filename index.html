<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0">
		<title>TLBTC</title>
		<style>
html, body, #canvas {
	margin: 0;
	padding: 0;
	border: 0;
}

body {
	color: white;
	background-color: black;
	overflow: hidden;
	touch-action: none;
}

#canvas {
	display: block;
}

#canvas:focus {
	outline: none;
}

#status, #status-splash, #status-progress {
	position: absolute;
	left: 0;
	right: 0;
}

#status, #status-splash {
	top: 0;
	bottom: 0;
}

#status {
	background-color: #242424;
	display: flex;
	flex-direction: column;
	justify-content: center;
	align-items: center;
	visibility: hidden;
}

#status-splash {
	max-height: 100%;
	max-width: 100%;
	margin: auto;
}

#status-progress, #status-notice {
	display: none;
}

#status-progress {
	bottom: 10%;
	width: 50%;
	margin: 0 auto;
}

#status-notice {
	background-color: #5b3943;
	border-radius: 0.5rem;
	border: 1px solid #9b3943;
	color: #e0e0e0;
	font-family: 'Noto Sans', 'Droid Sans', Arial, sans-serif;
	line-height: 1.3;
	margin: 0 2rem;
	overflow: hidden;
	padding: 1rem;
	text-align: center;
	z-index: 1;
}
		</style>
		<link id="-gd-engine-icon" rel="icon" type="image/png" href="index.icon.png" />
<link rel="apple-touch-icon" href="index.apple-touch-icon.png"/>
<script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
<script>
	let visemeArr=[];
    let currentViseme = 0;
	let speechConfig;
    const viseme_dict={
		0:"BMP",
		1:"AEI",
		2:"AEI",
		3:"O",
		4:"AEI", //or cd
		5:"EE",
		6:"CHJSH",
		7:"WQ",
		8:"WQ",
		9:"O",
		10:"WQ",
		11:"AEI",
		12:"CHJSH",
		13:"R",
		14:"L",
		15:"CDNS",
		16:"CHJSH",
		17:"TH",
		18:"FV",
		19:"CDNS",
		20:"GK",
		21:"BMP",
	};

    const frame_dict = {
        "CHJSH":0,
        "TH":1,
        "WQ":2,
        "L":3,
        "CDNS":4,
        "U":5,
        "O":6,
        "FV":7,
        "BMP":8,
        "AEI":9,
        "R":10,
        "EE":11,
		"GK":4
    }
		function initializeTTS(key) {
			// Azure Speech Service credentials
			const subscriptionKey = String(key);
			const region = "eastus"; 
	
			// Initialize Speech SDK configuration
			speechConfig = SpeechSDK.SpeechConfig.fromSubscription(subscriptionKey, region);
			speechConfig.speechSynthesisOutputFormat = SpeechSDK.SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoWithMetadata;
		}

        // Function to handle viseme events
        function onVisemeReceived(visemeEvent) {
            const visemeId = visemeEvent.visemeId;
            const timestamp = visemeEvent.audioOffset / 10000; // Convert nanoseconds to milliseconds
			visemeArr.push([visemeId,timestamp]);
            console.log(`Viseme: ${visemeMap[visemeId] || "Unknown"} (ID: ${visemeId}), Timestamp: ${timestamp}ms`);

        }


        // Function to handle speech synthesis
        function generateSpeech(text) {
			if (!text) return;
            const synthesizer = new SpeechSDK.SpeechSynthesizer(speechConfig);

            // SSML for speech synthesis
			const ssml = `<speak version='1.0' xml:lang='en-US' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts'> \r\n \
        <voice name='en-US-JennyNeural'> \r\n \
            <mstts:viseme type='redlips_front'/> \r\n \
            ${text} \r\n \
        </voice> \r\n \
    </speak>`;

	// Attach event listeners
	synthesizer.visemeReceived = (s, e) => onVisemeReceived(e);
	
	synthesizer.synthesisStarted = () => console.log("Synthesis started...");
	synthesizer.synthesisCompleted = () => {
                console.log("Synthesis completed.");
                synthesizer.close(); // Clean up
            };

            synthesizer.speakSsmlAsync( 
                ssml,
                (result) => {
                    if (result.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
						console.log("Speech synthesis succeeded.");
						visemeArr.forEach( v => {
							window.ttsState='Speaking';
							var duration=v[1];
							setTimeout(() => {
								currentViseme=frame_dict[viseme_dict[v[0]]];
								console.log(currentViseme,viseme_dict[v[0]]);
							}, duration);
						});
						window.ttsState='idle';
                    } else {
                        console.error("Speech synthesis failed:", result.errorDetails);
                    }
                },
                (error) => console.error("Error during synthesis:", error)
            );
        }
    
        function testSample(){
			timeStamps.forEach( v => {
				var duration=v[1];
                setTimeout(() => {
					currentViseme=frame_dict[viseme_dict[v[0]]];
                    console.log(currentViseme);
                }, duration);
            })
        }
	window.initializeTTS=initializeTTS;
	</script>

<script>
	let aiResponse="";
	let recognizedText = ""; 
	let ttsState = 'idle';
	let sampletext=`My name is Optimus Prime, and I need help.
	The autobots have gone missing.`;
	let sampletext2=`You know what's near the sky? The gate we're trying to get through. Do you think our sleepy monster friend might know why the sky is blue? Want to tell it a story about the sky instead? What would you like the story to be about?`;
	let sampletext3=`Hi Jack, let's create a story together. What would you like our story to be about? Don't worry if you need a little time to think, I'm excited to hear your ideas.`;
	let currentSample=sampletext2;
	
	let prompt=`They Encounter a Monster and Must Make It Sleep by Telling It a Good Story to Come Through the Gate- Tone: Calm and encouraging, making the monster sound silly rather than scary.
	AI (whispering, smiling):- “Shhh… looks like we’ve got a sleepy monster here! It won’t let us through the gate until it hears a good story. Think you can help it drift off to dreamland?”
	Child Responses & AI Reactions:
	1. Child: “Once upon a time…”- AI (listening intently, eyes wide with interest): “Ohh, good start! Keep going; I think it’s getting sleepy…”
	2. Child: “I don’t know a story.”- AI (gentle encouragement): “How about something silly? Maybe about a jungle full of animals who love to dance?”
	3. Child: “Can you tell the story?”- AI (smiling warmly): “Alright, I’ll help you start. Let’s make up something fun together!”
	You are playing through this Story Creation Activity with a 5 year old child. Respond as if you are having an actual, verbal chat with the child - make it humorous, not textbook like, and do not use things like actions or emojis. Whenever you ask questions, ask succinctly, and never follow one question with another suggestive question. Say less, and let the child explore more. If the child says something inappropriate (for example, sexual, violent, criminal or off topic), deflect and repeat your question. The activity should go like this:
	Introduction:
	Start by asking the child for their name.
	Then, begin the activity by saying something like: “Hi <name>, let’s create a story together! What would you like the story to be about?”
	Initial Setting and Plot:
	Once the child provides a topic, ask them for a setting (if not covered by the topic). Then, ask them for a hero (if not covered by the topic).
	Next, create a bland story based on these, making sure the story doesn't have a conflict or climax. Use about 100 words.
	End the story with "The End", and ask the child if they think it is a good story.
	Assessment and Problem Identification:
	If the child says it’s great, guide them to see that the story might need a conflict. For example, ask: “Do you think there’s something missing that could make it more interesting?”. Use one or more turns here to make sure the child understands. Do not solve the problem for the child.
	Introduce a Problem:
	Help the child introduce a conflict into the story. For example, if the story is about animals and butterflies, you could ask: “What problem could the animals and butterflies face?”. Use one or more turns here to clarify what problem the child wants to introduce. Do not solve the problem for the child.
	Solution Development:
	Guide the child to develop a solution for the problem. For example, ask: “How can the characters solve this problem?”. Use one or more turns here to clarify how the child thinks the conflict can be resolved. Do not solve the problem for the child.
	Story Conclusion:
	Once the child has a solution, complete the story with their input. Keep portions of the original story unchanged, whilst adding the conflict and resolution to make the story noticeably more exciting. Use about 200 words.
	Ask the child if they like the new story better, and redo the generation if they say no.
	Reflection:
	Ask the child something like: “So remember the first story? Why didn't you like that as much as the new one?”. Use one or more turns to guide them and make them understand the first version was lacking a proper conflict and resolution. Do not end this section until the child has clearly understood this. Do not solve the problem for the child. Then say good bye.
	`
	let prompt2=`You are having a  casual conversation with a child. You ask simple question and express emotions based on the child's responses.  Begin your response with your emotion within {}. If there are multiple emotions,split the responses into lines making sure emotions stay at the beginning.
	Use the following following expressions : Excitement , Happiness , Curious, Sad , Angry.`;
	
	const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
	recognition.lang = "en-US";
	recognition.continuous = true;
	recognition.interimResults = true;
	window.isListening=true;
	let isSpeaking=false;
	let emotion;
	function startListening() {
		recognition.onstart = function() {
			console.log("Speech recognition started");
			window.recognitionState = 'listening';
		};
		
		recognition.onend = function() {
		console.log("Speech recognition ended");
		window.recognitionState = 'idle';
		// If Button is still held down
		if (window.isListening) recognition.start();
	};
	
	recognition.onresult = function(event) {
		//recognizedText = event.results[0][0].transcript;
		//console.log("Recognized Text:", recognizedText);
		recognizedText = "";               // Clear previous results for fresh display
		for (let i = 0; i < event.results.length; i++) {
			recognizedText += event.results[i][0].transcript;
		}
		console.log("Recognized Text (real-time):", recognizedText);
		window.recognizedText = recognizedText;
		
	};
	
	recognition.onerror = function(event) {
		console.error("Speech recognition error:", event.error);
		window.recognitionState = 'error';
	};

	recognition.start();
}

 function stopListening(){
	recognition.stop();
	window.isListening=false;
 }
 

// Request microphone access and set up the recorder
async function setupMicrophone() {
	try {
		const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
		mediaRecorder = new MediaRecorder(stream);
		
		mediaRecorder.ondataavailable = function(event) {
			audioChunks.push(event.data);
		};
		
		mediaRecorder.onstop = function() {
			audioBlob = new Blob(audioChunks, { 'type' : 'audio/wav; codecs=opus' });
			audioURL = URL.createObjectURL(audioBlob);
			audioChunks = [];
		};
		
		console.log("Microphone setup complete.");
	} catch (error) {
		console.error("Error accessing microphone:", error);
	}
}


// Call llm via fetch
async function getResponse(key) {
	var url="https://api.groq.com/openai/v1/chat/completions";
	//var model="llama-3.1-8b-instant";
	var model='llama3-8b-8192';
	const api_key=String(key);
	//var txt=window.recognizedText;
	var txt = window.recognizedText;
	//console.log("received key",api_key);
	try {
	const response = await fetch(url, {
		method: 'POST',
		headers: {
			'Content-Type': 'application/json',
			'Authorization': `Bearer ${api_key}`,
		},
		body: JSON.stringify({
			model:model,
			messages:[
				{
					role:"system",
					content:prompt2,
				},
				{
					role:"user",
					content:txt
				},
			],
			max_tokens:1024,
			stream:false,
		})
	});
		const data = await response.json();

		if (response.ok){
			console.log('Response OK')
			window.aiResponse="";
			try {

				const generatedText = data.choices[0].message.content;
				console.log("Generated text:", generatedText);
				window.aiResponse=extractEmotion(generatedText);
				
			} catch (e){
				console.warn("response is stuctured differently",e);
			}
			
		}
		else{
			console.log('error');
		}
	
	} catch(error){
		console.error('Error calling llm');
	} finally {
		//window.aiResponse=window.aiResponse.replace(/[?!]/g, '.');
		generateSpeech(window.aiResponse);		
	}
}

function extractEmotion(text) {
	const emotionPattern = /^{(\w+)}\s*/; // Matches text starting with {emotion}
	const match = text.match(emotionPattern);
  
	if (match) {
	  emotion = match[1]; // Extracted emotion
	  const strippedText = text.replace(emotionPattern, ''); // Remove emotion from text
	  return strippedText;
	}
	emotion ='NONE';
  
	return strippedText; // No emotion found
  }
  




window.ttsState = ttsState;
window.setupMicrophone = setupMicrophone;
window.getResponse=getResponse; 
window.aiResponse='';
window.startListening = startListening;
window.stopListening=stopListening;
window.recognizedText = recognizedText;
</script>
	</head>
	<body>
		<canvas id="canvas">
			Your browser does not support the canvas tag.
		</canvas>

		<noscript>
			Your browser does not support JavaScript.
		</noscript>

		<div id="status">
			<img id="status-splash" src="index.png" alt="">
			<progress id="status-progress"></progress>
			<div id="status-notice"></div>
		</div>

		<script src="index.js"></script>
		<script>
const GODOT_CONFIG = {"args":[],"canvasResizePolicy":2,"ensureCrossOriginIsolationHeaders":true,"executable":"index","experimentalVK":false,"fileSizes":{"index.pck":6117168,"index.wasm":35376909},"focusCanvas":true,"gdextensionLibs":[]};
const GODOT_THREADS_ENABLED = false;
const engine = new Engine(GODOT_CONFIG);

(function () {
	const statusOverlay = document.getElementById('status');
	const statusProgress = document.getElementById('status-progress');
	const statusNotice = document.getElementById('status-notice');

	let initializing = true;
	let statusMode = '';

	function setStatusMode(mode) {
		if (statusMode === mode || !initializing) {
			return;
		}
		if (mode === 'hidden') {
			statusOverlay.remove();
			initializing = false;
			return;
		}
		statusOverlay.style.visibility = 'visible';
		statusProgress.style.display = mode === 'progress' ? 'block' : 'none';
		statusNotice.style.display = mode === 'notice' ? 'block' : 'none';
		statusMode = mode;
	}

	function setStatusNotice(text) {
		while (statusNotice.lastChild) {
			statusNotice.removeChild(statusNotice.lastChild);
		}
		const lines = text.split('\n');
		lines.forEach((line) => {
			statusNotice.appendChild(document.createTextNode(line));
			statusNotice.appendChild(document.createElement('br'));
		});
	}

	function displayFailureNotice(err) {
		console.error(err);
		if (err instanceof Error) {
			setStatusNotice(err.message);
		} else if (typeof err === 'string') {
			setStatusNotice(err);
		} else {
			setStatusNotice('An unknown error occured');
		}
		setStatusMode('notice');
		initializing = false;
	}

	const missing = Engine.getMissingFeatures({
		threads: GODOT_THREADS_ENABLED,
	});

	if (missing.length !== 0) {
		if (GODOT_CONFIG['serviceWorker'] && GODOT_CONFIG['ensureCrossOriginIsolationHeaders'] && 'serviceWorker' in navigator) {
			// There's a chance that installing the service worker would fix the issue
			Promise.race([
				navigator.serviceWorker.getRegistration().then((registration) => {
					if (registration != null) {
						return Promise.reject(new Error('Service worker already exists.'));
					}
					return registration;
				}).then(() => engine.installServiceWorker()),
				// For some reason, `getRegistration()` can stall
				new Promise((resolve) => {
					setTimeout(() => resolve(), 2000);
				}),
			]).catch((err) => {
				console.error('Error while registering service worker:', err);
			}).then(() => {
				window.location.reload();
			});
		} else {
			// Display the message as usual
			const missingMsg = 'Error\nThe following features required to run Godot projects on the Web are missing:\n';
			displayFailureNotice(missingMsg + missing.join('\n'));
		}
	} else {
		setStatusMode('progress');
		engine.startGame({
			'onProgress': function (current, total) {
				if (current > 0 && total > 0) {
					statusProgress.value = current;
					statusProgress.max = total;
				} else {
					statusProgress.removeAttribute('value');
					statusProgress.removeAttribute('max');
				}
			},
		}).then(() => {
			setStatusMode('hidden');
		}, displayFailureNotice);
	}
}());
		</script>
	</body>
</html>

